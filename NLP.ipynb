{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsk5LlOI9Bn0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "581f9517-9ba6-4e26-c89a-68f493cabeb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/176.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (1.22.4)\n",
            "Collecting boto3 (from pytorch-transformers)\n",
            "  Downloading boto3-1.28.15-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (4.65.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2022.10.31)\n",
            "Collecting sentencepiece (from pytorch-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses (from pytorch-transformers)\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->pytorch-transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->pytorch-transformers) (16.0.6)\n",
            "Collecting botocore<1.32.0,>=1.31.15 (from boto3->pytorch-transformers)\n",
            "  Downloading botocore-1.31.15-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch-transformers)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->pytorch-transformers)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (3.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.15->boto3->pytorch-transformers) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->pytorch-transformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->pytorch-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895239 sha256=99aabacc17814b2d7dbee012763236b52d0c05abad0468603bac7e1685c83cfe\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, jmespath, botocore, s3transfer, boto3, pytorch-transformers\n",
            "Successfully installed boto3-1.28.15 botocore-1.31.15 jmespath-1.0.1 pytorch-transformers-1.2.0 s3transfer-0.6.1 sacremoses-0.0.53 sentencepiece-0.1.99\n",
            "Collecting kobert_tokenizer\n",
            "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-3gve5mp4/kobert-tokenizer_10a25fc614ec4f3388337ba9d9dc253c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-3gve5mp4/kobert-tokenizer_10a25fc614ec4f3388337ba9d9dc253c\n",
            "  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kobert_tokenizer\n",
            "  Building wheel for kobert_tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert_tokenizer: filename=kobert_tokenizer-0.1-py3-none-any.whl size=4632 sha256=488b12bd61a5bc618d5f9659b6e084d59f63da5f8b96b3573cad8cb2f8291756\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ptkozl_m/wheels/e9/1a/3f/a864970e8a169c176befa3c4a1e07aa612f69195907a4045fe\n",
            "Successfully built kobert_tokenizer\n",
            "Installing collected packages: kobert_tokenizer\n",
            "Successfully installed kobert_tokenizer-0.1\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n",
            "Cloning into 'nsmc'...\n",
            "remote: Enumerating objects: 14763, done.\u001b[K\n",
            "remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n",
            "Receiving objects: 100% (14763/14763), 56.19 MiB | 24.76 MiB/s, done.\n",
            "Resolving deltas: 100% (1749/1749), done.\n",
            "Updating files: 100% (14737/14737), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-transformers\n",
        "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n",
        "!pip install transformers\n",
        "!git clone https://github.com/e9t/nsmc.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer,AutoModelForSequenceClassification,pipeline\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "import urllib.request\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tqdm import tqdm\n",
        "from transformers import TFBertForSequenceClassification\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "from transformers import BertModel,BertForTokenClassification\n",
        "import sentencepiece as spm\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "_IkGMKk59PZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이저 지정\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"snunlp/KR-FinBert\",return_tensors='pt')"
      ],
      "metadata": {
        "id": "ZTtX0scG9X4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 평가할 금융분석 데이터 불러오기\n",
        "train_df = pd.read_csv('./nsmc/ratings_train.txt', sep='\\t')\n",
        "test_df = pd.read_csv('./nsmc/ratings_test.txt', sep='\\t')\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv\", filename='finance_data.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWi9hZmf9g8P",
        "outputId": "7188ae2a-e952-419e-cec2-20f0b0d62d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('finance_data.csv', <http.client.HTTPMessage at 0x7cbcc8c6c070>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가할 금융분석 데이터 불러오기 => 5천개의 데이터셋\n",
        "data = pd.read_csv('finance_data.csv')\n",
        "del data['sentence']\n",
        "\n",
        "# 0: 중립\n",
        "# 1: 긍정\n",
        "# 2: 부정\n",
        "data['labels'] = data['labels'].replace(['neutral', 'positive', 'negative'],[0, 1, 2])\n",
        "\n",
        "# 중복 제거\n",
        "duplicate = data[data.duplicated()]\n",
        "data.drop_duplicates(subset=['kor_sentence'], inplace=True)\n",
        "print('총 샘플의 수 :',len(data))\n",
        "\n",
        "# 중립 제거\n",
        "data=data[data['labels']!=0]\n",
        "data.shape"
      ],
      "metadata": {
        "id": "7d5L74eD9g-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9002d099-4df3-4cb7-99c5-0aa90eb2b4e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 수 : 4827\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1966, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복 제거\n",
        "duplicate = data[data.duplicated()]\n",
        "data.drop_duplicates(subset=['kor_sentence'], inplace=True)\n",
        "print('총 샘플의 수 :',len(data))"
      ],
      "metadata": {
        "id": "qk43W6OS9nU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3312498-b16c-454f-a725-8f906feed06e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 수 : 1966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중립 제거\n",
        "data=data[data['labels']!=0]\n",
        "data"
      ],
      "metadata": {
        "id": "JmcHVrNlaFBZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "67dcdef8-caa5-48e8-cc67-99da7acaf15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      labels                                       kor_sentence\n",
              "2          2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...\n",
              "3          1  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...\n",
              "4          1  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...\n",
              "5          1  ASPOCOMP의 성장기에 대한 자금 조달은 기술적으로 더 까다로운 HDI 인쇄 회...\n",
              "6          1  2010년 4분기 Componenta의 순매출은 전년 동기의 7600만 유로에서 2...\n",
              "...      ...                                                ...\n",
              "4840       2  헬싱키 톰슨 파이낸셜 - 카고텍의 주가는 화물 취급 그룹이 4월부터 6월까지 3개월...\n",
              "4841       2  런던 마켓워치 -- 은행주의 반등이 FTSE 100지수의 약세를 상쇄하지 못하면서 ...\n",
              "4843       2  영업이익은 2007년 68.8 mn에서 35.4 mn으로 떨어졌으며, 선박 판매 이...\n",
              "4844       2  페이퍼 부문 순매출은 2008년 2분기 241.1 mn에서 2009년 2분기 221...\n",
              "4845       2   핀란드에서의 판매는 1월에 10.5% 감소한 반면, 국외에서의 판매는 17% 감소했다.\n",
              "\n",
              "[1966 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-69821d24-69b7-42a3-b34d-073ec528a3b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>kor_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>ASPOCOMP의 성장기에 대한 자금 조달은 기술적으로 더 까다로운 HDI 인쇄 회...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>2010년 4분기 Componenta의 순매출은 전년 동기의 7600만 유로에서 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4840</th>\n",
              "      <td>2</td>\n",
              "      <td>헬싱키 톰슨 파이낸셜 - 카고텍의 주가는 화물 취급 그룹이 4월부터 6월까지 3개월...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4841</th>\n",
              "      <td>2</td>\n",
              "      <td>런던 마켓워치 -- 은행주의 반등이 FTSE 100지수의 약세를 상쇄하지 못하면서 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4843</th>\n",
              "      <td>2</td>\n",
              "      <td>영업이익은 2007년 68.8 mn에서 35.4 mn으로 떨어졌으며, 선박 판매 이...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4844</th>\n",
              "      <td>2</td>\n",
              "      <td>페이퍼 부문 순매출은 2008년 2분기 241.1 mn에서 2009년 2분기 221...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4845</th>\n",
              "      <td>2</td>\n",
              "      <td>핀란드에서의 판매는 1월에 10.5% 감소한 반면, 국외에서의 판매는 17% 감소했다.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1966 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69821d24-69b7-42a3-b34d-073ec528a3b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-f55a32ff-c84c-4c22-b7c5-b7df3255ccd7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f55a32ff-c84c-4c22-b7c5-b7df3255ccd7')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-f55a32ff-c84c-4c22-b7c5-b7df3255ccd7 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69821d24-69b7-42a3-b34d-073ec528a3b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69821d24-69b7-42a3-b34d-073ec528a3b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 데이터와 label 데이터 지정\n",
        "data.reset_index(inplace=True,drop=True)\n",
        "data_kr=data['kor_sentence']\n",
        "data_label=data['labels']"
      ],
      "metadata": {
        "id": "1di3Qf5t1Nt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mydrive 사용\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoL178epjY3n",
        "outputId": "d820f3b5-d882-498a-c158-5b0da4493463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer,AutoModelForSequenceClassification,pipeline\n",
        "\n",
        "# models = AutoModelForSequenceClassification.from_pretrained(\"snunlp/KR-FinBert\")\n",
        "\n",
        "models=AutoModelForSequenceClassification.from_pretrained(\"./drive/MyDrive/model_directory/\") # => KR-FinBert에서 weight 찾아서 저장후 불러온 모델\n",
        "\n",
        "classifier=pipeline(\"sentiment-analysis\",tokenizer=tokenizer,model=models,device=0) # pipeline을 사용하여 tokenizer와 model 연결후 감성분석"
      ],
      "metadata": {
        "id": "cpgz6aQk9v1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a00696bd-bc45-480a-f505-8f2dac52508d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at snunlp/KR-FinBert and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장한 모델 신경망 파라미터들\n",
        "# {\n",
        "#   \"_name_or_path\": \"snunlp/KR-FinBert\",\n",
        "#   \"architectures\": [\n",
        "#     \"BertForSequenceClassification\"\n",
        "#   ],\n",
        "#   \"attention_probs_dropout_prob\": 0.1,\n",
        "#   \"classifier_dropout\": null,\n",
        "#   \"gradient_checkpointing\": false,\n",
        "#   \"hidden_act\": \"gelu\",\n",
        "#   \"hidden_dropout_prob\": 0.1,\n",
        "#   \"hidden_size\": 768,\n",
        "#   \"initializer_range\": 0.02,\n",
        "#   \"intermediate_size\": 3072,\n",
        "#   \"layer_norm_eps\": 1e-12,\n",
        "#   \"max_position_embeddings\": 512,\n",
        "#   \"model_type\": \"bert\",\n",
        "#   \"num_attention_heads\": 12,\n",
        "#   \"num_hidden_layers\": 12,\n",
        "#   \"pad_token_id\": 0,\n",
        "#   \"position_embedding_type\": \"absolute\",\n",
        "#   \"torch_dtype\": \"float32\",\n",
        "#   \"transformers_version\": \"4.30.2\",\n",
        "#   \"type_vocab_size\": 2,\n",
        "#   \"use_cache\": true,\n",
        "#   \"vocab_size\": 20000\n",
        "# }\n"
      ],
      "metadata": {
        "id": "CRzs-ZeIK4A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# models.save_pretrained('./model_directory') => 모델 신경망 저장"
      ],
      "metadata": {
        "id": "UZehE5pfw-Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# results => label과 score가 담김\n",
        "# label_ => label만 추출\n",
        "results=[]\n",
        "label_=[]\n",
        "\n",
        "for text in data_kr:\n",
        "    result = classifier(text)\n",
        "    results.append(result)\n",
        "\n",
        "# label_에 긍,부정과 그에 대한 scrores 확률이 담김\n",
        "for i, result in enumerate(results):\n",
        "    for r in result:\n",
        "        label_.append(r['label']) # label로 긍정과 부정만 추출\n",
        "data['predict']=label_ # predict 컬럼에 담기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb8BtrHKweiq",
        "outputId": "d433022e-b0a5-4ada-f532-3da13cd894b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['predict'].value_counts(),data['labels'].value_counts() # 긍부정 label 비교"
      ],
      "metadata": {
        "id": "15FkrGmH5A64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4b00a7d-ed1e-4f5d-b0ff-7399d8bcb58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(LABEL_1    1255\n",
              " LABEL_0     711\n",
              " Name: predict, dtype: int64,\n",
              " 1    1362\n",
              " 2     604\n",
              " Name: labels, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['predict']=data['predict'].map({'LABEL_0':1,'LABEL_1':2})  # LABEL_0은 긍정, LABEL_1은 부정이므로 1,2로 긍정,부정을 나눔"
      ],
      "metadata": {
        "id": "SVi3sXoM5BAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = AutoModelForSequenceClassification.from_pretrained(\"snunlp/KR-FinBert\")\n",
        "\n",
        "classifier=pipeline(\"sentiment-analysis\",tokenizer=tokenizer,model=models,device=0) # pipeline을 사용하여 tokenizer와 model 연결후 감성분석\n",
        "\n",
        "results=[]\n",
        "label_=[]\n",
        "\n",
        "for text in data_kr:\n",
        "    result = classifier(text)\n",
        "    results.append(result)\n",
        "\n",
        "# label_에 긍,부정과 그에 대한 scrores 확률이 담김\n",
        "for i, result in enumerate(results):\n",
        "    for r in result:\n",
        "        label_.append(r['label']) # label로 긍정과 부정만 추출\n",
        "data['predict']=label_ # predict 컬럼에 담기\n",
        "\n",
        "data['predict']=data['predict'].map({'LABEL_0':1,'LABEL_1':2})\n",
        "\n",
        "TP = 0\n",
        "TN = 0\n",
        "FP = 0\n",
        "FN = 0\n",
        "\n",
        "dl = data['labels']\n",
        "dp = data['predict']\n",
        "\n",
        "for idx, da in enumerate(dl):\n",
        "    if (dp[idx] == 1) and (dl[idx] == 1):\n",
        "        TP += 1\n",
        "    elif (dp[idx] == 2) and (dl[idx] == 2):\n",
        "        TN += 1\n",
        "    elif (dp[idx] == 1) and (dl[idx] == 2):\n",
        "        FP += 1\n",
        "    elif (dp[idx] == 2) and (dl[idx] == 1):\n",
        "        FN += 1\n",
        "\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print('정밀도(Precision): ', precision)\n",
        "print('재현율(Recall): ', recall)\n",
        "print('F1 score: ', f1_score)\n",
        "print('정확도(Accuracy): ', accuracy)\n"
      ],
      "metadata": {
        "id": "iXe4dtXPvOhs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0e6d36-d662-4c1d-c059-3ca6f73a8a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정밀도(Precision):  0.7010036978341257\n",
            "재현율(Recall):  0.9743024963289281\n",
            "F1 score:  0.8153609831029186\n",
            "정확도(Accuracy):  0.7243031536113937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mydrive 사용\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# label있는 신세계 데이터 불러오기\n",
        "shin=pd.read_csv('/content/drive/MyDrive/shin_result.csv',header=0,index_col=0)"
      ],
      "metadata": {
        "id": "XAolCgpRnVh_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "669fa90d-ee2f-4ad3-ab6f-686592e0136f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shin=shin[shin['sentiment']!=0]\n",
        "shin=shin.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "r3wxyv7YotBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label있는 신세계 데이터 불러오기\n",
        "# 3000개의 데이터셋\n",
        "shin=pd.read_csv('/content/drive/MyDrive/shin_result.csv',header=0,index_col=0)\n",
        "shin=shin[shin['sentiment']!=0]\n",
        "shin=shin.reset_index(drop=True)\n",
        "shin['sentiment'].value_counts() # 2362개 긍정 , 568개 부정"
      ],
      "metadata": {
        "id": "dZp2FpM_0mRc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94abe1c7-a880-44d5-f30f-a6faf22014f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    2362\n",
              "2     486\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shin.drop_duplicates(subset=['title'], inplace=True) #중복제거"
      ],
      "metadata": {
        "id": "IZgt2hAMjodU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "shin_kr=shin['title']\n",
        "shin_lis=[]\n",
        "for text in shin_kr:\n",
        "    result = classifier(text)\n",
        "    shin_lis.append(result)\n",
        "\n",
        "shin_li=[]\n",
        "for i, result in enumerate(shin_lis):\n",
        "    for r in result:\n",
        "        shin_li.append(r['label'])\n",
        "shin['predict']=shin_li\n",
        "shin['predict']=shin['predict'].map({'LABEL_1':2,'LABEL_0':1})\n"
      ],
      "metadata": {
        "id": "kVw86M4zpOlZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d2a407-2c95-4110-b0d0-71dcd8d80e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shin['predict'].value_counts(),shin['sentiment'].value_counts()"
      ],
      "metadata": {
        "id": "0b23gQ5zpvkq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be4ce968-fa9e-46b9-d9ac-218513ad4e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1    2388\n",
              " 2     460\n",
              " Name: predict, dtype: int64,\n",
              " 1    2362\n",
              " 2     486\n",
              " Name: sentiment, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shin['predict']=shin['predict'].map({'LABEL_1':2,'LABEL_0':1})"
      ],
      "metadata": {
        "id": "Ag0c630Lp2ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP = 0\n",
        "TN = 0\n",
        "FP = 0\n",
        "FN = 0\n",
        "\n",
        "sent=shin['sentiment']\n",
        "pred=shin['predict']\n",
        "for idx, da in enumerate(sent):\n",
        "    if (pred[idx] == 1) and (sent[idx] == 1):\n",
        "        TP += 1\n",
        "    elif (pred[idx] == 2) and (sent[idx] == 2):\n",
        "        TN += 1\n",
        "    elif (pred[idx] == 1) and (sent[idx] == 2):\n",
        "        FP += 1\n",
        "    elif (pred[idx] == 2) and (sent[idx] == 1):\n",
        "        FN += 1\n",
        "\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print('정밀도(Precision): ', precision)\n",
        "print('재현율(Recall): ', recall)\n",
        "print('F1 score: ', f1_score)\n",
        "print('정확도(Accuracy): ', accuracy)\n"
      ],
      "metadata": {
        "id": "E5lDI0Uk2kLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c589ba8-6dfd-40e2-8ea7-f9d5b7902f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정밀도(Precision):  0.8189245887159103\n",
            "재현율(Recall):  0.8779592803030303\n",
            "F1 score:  0.8474150242787775\n",
            "정확도(Accuracy):  0.7958610846812559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shin"
      ],
      "metadata": {
        "id": "ePxL6i9huTSg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "1d4f6c2c-229f-46b5-b3c3-3198951e62f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  date                                      title  sentiment  \\\n",
              "0     2023-04-18 16:05  [현장] 현대백화점 디즈니스토어 문전성시, 정지선 오프라인 '경험'을 판다          1   \n",
              "1     2023-04-13 20:01       현대백화점-디즈니 손잡았다…올해 안에 '디즈니스토어' 네 곳 연다          1   \n",
              "2     2023-04-07 13:56           현대백화점, 한국관광공사 맞손…글로벌 MZ세대 공략 나선다          1   \n",
              "3     2023-04-07 17:25              현대백화점, 관광공사와 손잡고 글로벌 MZ세대 잡는다          1   \n",
              "4     2023-03-07 07:53                    현대백화점, 新성장동력 '비건뷰티' 키운다          1   \n",
              "...                ...                                        ...        ...   \n",
              "3583  2023-03-24 09:25           \"그래도 믿을 건 중국 뿐?\"…부진한 의류株, 돌파구 있나          1   \n",
              "3584  2023-05-23 17:49         \"그동안 몰라봐서 미안\"…매출 47% 뛰게 만든 '이것'의 힘          1   \n",
              "3585  2023-02-21 08:53       \"고물가에 '벌크업 쇼핑' 뜬다\"…G마켓, 대용량제품 매출 3배↑          1   \n",
              "3586  2023-02-21 11:56              \"고물가 시대\"…G마켓, 대용량 제품 매출 3배 증가          1   \n",
              "3589  2023-05-24 11:01          \"10대도 60대도 스포츠 의류·용품은 이 앱이 싹쓸이했다\"          1   \n",
              "\n",
              "      predict  \n",
              "0           1  \n",
              "1           1  \n",
              "2           1  \n",
              "3           1  \n",
              "4           1  \n",
              "...       ...  \n",
              "3583        1  \n",
              "3584        1  \n",
              "3585        1  \n",
              "3586        1  \n",
              "3589        1  \n",
              "\n",
              "[2848 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-9f5c0150-c3fc-4ede-a0bd-0775f9472a15\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-04-18 16:05</td>\n",
              "      <td>[현장] 현대백화점 디즈니스토어 문전성시, 정지선 오프라인 '경험'을 판다</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-04-13 20:01</td>\n",
              "      <td>현대백화점-디즈니 손잡았다…올해 안에 '디즈니스토어' 네 곳 연다</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-04-07 13:56</td>\n",
              "      <td>현대백화점, 한국관광공사 맞손…글로벌 MZ세대 공략 나선다</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-04-07 17:25</td>\n",
              "      <td>현대백화점, 관광공사와 손잡고 글로벌 MZ세대 잡는다</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-03-07 07:53</td>\n",
              "      <td>현대백화점, 新성장동력 '비건뷰티' 키운다</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3583</th>\n",
              "      <td>2023-03-24 09:25</td>\n",
              "      <td>\"그래도 믿을 건 중국 뿐?\"…부진한 의류株, 돌파구 있나</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3584</th>\n",
              "      <td>2023-05-23 17:49</td>\n",
              "      <td>\"그동안 몰라봐서 미안\"…매출 47% 뛰게 만든 '이것'의 힘</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3585</th>\n",
              "      <td>2023-02-21 08:53</td>\n",
              "      <td>\"고물가에 '벌크업 쇼핑' 뜬다\"…G마켓, 대용량제품 매출 3배↑</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3586</th>\n",
              "      <td>2023-02-21 11:56</td>\n",
              "      <td>\"고물가 시대\"…G마켓, 대용량 제품 매출 3배 증가</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3589</th>\n",
              "      <td>2023-05-24 11:01</td>\n",
              "      <td>\"10대도 60대도 스포츠 의류·용품은 이 앱이 싹쓸이했다\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2848 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f5c0150-c3fc-4ede-a0bd-0775f9472a15')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-232e0481-fd2e-4f24-989f-20beaca72795\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-232e0481-fd2e-4f24-989f-20beaca72795')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-232e0481-fd2e-4f24-989f-20beaca72795 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f5c0150-c3fc-4ede-a0bd-0775f9472a15 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f5c0150-c3fc-4ede-a0bd-0775f9472a15');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    }
  ]
}